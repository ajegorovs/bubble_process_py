{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, itertools, networkx as nx, sys, copy,  cv2, os, glob, re, pickle, time as time_lib\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "def track_time(reset = False):\n",
    "    if reset:\n",
    "        track_time.last_time = time_lib.time()\n",
    "        return '(Initializing time counter)'\n",
    "    else:\n",
    "        current_time = time_lib.time()\n",
    "        time_passed = current_time - track_time.last_time\n",
    "        track_time.last_time = current_time\n",
    "        return f'({time_passed:.2f} s)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainOutputFolder     = r'.\\post_tests'                           # descritive project name e.g [gallium_bubbles, water_bubbles]\n",
    "mainOutputSubFolders =  ['Field OFF Series 7', 'sccm150-meanFix']   \n",
    "inputImageFolder     = r'E:\\relocated\\Downloads\\150 sccm' #\n",
    "\n",
    "intervalStart   = 1                           # start with this ID\n",
    "numImages       = 1999                         # how many images you want to analyze.\n",
    "intervalStop    = intervalStart + numImages     # images IDs \\elem [intervalStart, intervalStop); start-end will be updated depending on available data.\n",
    "\n",
    "useMeanWindow   = 0                             # averaging intervals will overlap half widths, read more below\n",
    "N               = 700                           # averaging window width\n",
    "rotateImageBy   = cv2.ROTATE_180                # -1= no rotation, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180 \n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.7; thickness = 4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:                               # prep image links, get min/max image indexes\n",
    "    # ================================================================================================\n",
    "    # ============================= GET PATHS TO IMAGES AND RESORT BY ID =============================\n",
    "    # 1) get image links\n",
    "    # 2) extract integers in name [.\\img3509, .\\img351, .\\img3510, ....] -> [3509, 351, 3510, ...]\n",
    "    # 3) filter by index \n",
    "    # 4) sort order by index [.\\img3509, .\\img351, .\\img3510, ...] -> [.\\img351, .\\img3509, .\\img3510, ...]\n",
    "    imageLinks = glob.glob(inputImageFolder + \"**/*.bmp\", recursive=True) \n",
    "    if len(imageLinks) == 0:\n",
    "        input(\"No files inside directory, copy them and press any key to continue...\")\n",
    "        imageLinks = glob.glob(inputImageFolder + \"**/*.bmp\", recursive=True)                                          # 1)\n",
    "\n",
    "    extractIntergerFromFileName = lambda x: int(re.findall('\\d+', os.path.basename(x))[0])                             # 2)\n",
    "    imageLinks = list(filter(lambda x: intervalStart <= extractIntergerFromFileName(x) < intervalStop , imageLinks))   # 3)\n",
    "    imageLinks.sort(key=extractIntergerFromFileName)                                                                   # 4)\n",
    "\n",
    "    intervalStart   = extractIntergerFromFileName(imageLinks[0])        # update start index, so its captures in subfolder name.\n",
    "    intervalStop    = extractIntergerFromFileName(imageLinks[-1])       # update end index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========================================================================================================//\n",
    "======================================== BUILD PROJECT FOLDER HIERARCHY ================================//\n",
    "--------------------------------------------------------------------------------------------------------//\n",
    "------------------------------------ CREATE MAIN PROJECT, SUBPROJECT FOLDERS ---------------------------//\n",
    "\"\"\"\n",
    "if not os.path.exists(mainOutputFolder): os.mkdir(mainOutputFolder)  \n",
    "mainOutputSubFolders.append(f\"{intervalStart:05}-{intervalStop:05}\")       # sub-project folder hierarhy e.g [exp setup, parameter, subset of data]\n",
    "\n",
    "for folderName in mainOutputSubFolders:     \n",
    "    mainOutputFolder = os.path.join(mainOutputFolder, folderName)               \n",
    "    if not os.path.exists(mainOutputFolder): os.mkdir(mainOutputFolder)\n",
    "\n",
    "# -------------------------------- CREATE VARIOUS OUTPUT FOLDERS -------------------------\n",
    "\n",
    "imageFolder        = os.path.join(mainOutputFolder, 'images'    )\n",
    "stagesFolder       = os.path.join(mainOutputFolder, 'stages'    )\n",
    "dataArchiveFolder  = os.path.join(mainOutputFolder, 'archives'  )\n",
    "graphsFolder       = os.path.join(mainOutputFolder, 'graphs'    )\n",
    "\n",
    "[os.mkdir(folder) for folder in (imageFolder, stagesFolder, dataArchiveFolder, graphsFolder) if not os.path.exists(folder)]\n",
    "\n",
    "imageFolder_pre_run = os.path.join(imageFolder, 'prerun')\n",
    "if not os.path.exists(imageFolder_pre_run): os.mkdir(imageFolder_pre_run)\n",
    "\n",
    "imageFolder_output = os.path.join(imageFolder, 'output')\n",
    "if not os.path.exists(imageFolder_output): os.mkdir(imageFolder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_modues = r'.\\modules'      # os.path.join(mainOutputFolder,'modules')\n",
    "sys.path.append(path_modues)    \n",
    "\n",
    "# NOTE: IF YOU USE MODULES, DONT FORGET EMPTY \"__init__.py\" FILE INSIDE MODULES FOLDER\n",
    "# NOTE: path_modules_init = os.path.join(path_modues, \"__init__.py\")\n",
    "# NOTE: if not os.path.exists(path_modules_init):  with open(path_modules_init, \"w\") as init_file: init_file.write(\"\")\n",
    "\n",
    "#--------------------------- IMPORT CUSTOM FUNCITONS -------------------------------------\n",
    "from cropGUI import cropGUI\n",
    "\n",
    "from graphs_brects import (overlappingRotatedRectangles)\n",
    "\n",
    "from image_processing import (convertGray2RGB, undistort)\n",
    "\n",
    "from bubble_params  import (centroid_area_cmomzz, centroid_area)\n",
    "\n",
    "from graphs_general import (graph_extract_paths, find_paths_from_to_multi, graph_check_paths, get_connected_components,\n",
    "                            comb_product_to_graph_edges, for_graph_plots,  extract_clusters_from_edges,\n",
    "                            set_custom_node_parameters, G2_set_parameters, get_event_types_from_segment_graph)\n",
    "\n",
    "from graphs_general import (G, G2, key_nodes, keys_segments, G2_t_start, G2_t_end, G2_n_from, G2_n_to, G2_edge_dist, G_time, G_area, G_centroid, G_owner, G_owner_set)\n",
    "\n",
    "from interpolation import (interpolate_trajectory, extrapolate_find_k_s, interpolateMiddle1D_2, decide_k_s)\n",
    "\n",
    "from misc import (cyclicColor, timeHMS, modBR, rect2contour, combs_different_lengths, sort_len_diff_f,\n",
    "                  disperse_nodes_to_times, disperse_composite_nodes_into_solo_nodes, find_key_by_value, CircularBuffer, CircularBufferReverse, \n",
    "                  split_into_bins, lr_reindex_masters, dfs_pred, dfs_succ, old_conn_2_new, lr_evel_perm_interp_data, lr_weighted_sols, \n",
    "                  save_connections_two_ways, save_connections_merges, save_connections_splits, itertools_product_length, conflicts_stage_1, \n",
    "                  conflicts_stage_2, conflicts_stage_3, edge_crit_func, two_crit_many_branches, find_final_master_all,\n",
    "                  zp_process, f121_disperse_stray_nodes, f121_interpolate_holes, f121_calc_permutations, f121_precompute_params, f121_get_evolutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initializing time counter)\n"
     ]
    }
   ],
   "source": [
    "cropMaskName = \"-\".join(mainOutputSubFolders[:2])+'-crop'\n",
    "cropMaskPath = os.path.join(os.path.join(*mainOutputFolder.split(os.sep)[:-1]), f\"{cropMaskName}.png\")\n",
    "cropMaskMissing = True if not os.path.exists(cropMaskPath) else False\n",
    "\n",
    "graphsPath          =   os.path.join(dataArchiveFolder  ,  \"graphs.pickle\"    )\n",
    "segmentsPath        =   os.path.join(dataArchiveFolder  ,  \"segments.pickle\"  )\n",
    "contoursHulls       =   os.path.join(dataArchiveFolder  ,  \"contorus.pickle\"  )\n",
    "mergeSplitEvents    =   os.path.join(dataArchiveFolder  ,  \"ms-events.pickle\" )\n",
    "\n",
    "                     \n",
    "meanImagePath       =   os.path.join(dataArchiveFolder  ,  \"mean.npz\"         )\n",
    "meanImagePathArr    =   os.path.join(dataArchiveFolder  ,  \"meanArr.npz\"      )\n",
    "                     \n",
    "archivePath         =   os.path.join(stagesFolder       ,  \"croppedImageArr.npz\"        )\n",
    "binarizedArrPath    =   os.path.join(stagesFolder       ,  \"binarizedImageArr.npz\"      )\n",
    "post_binary_data    =   os.path.join(stagesFolder       ,  \"intermediate_data.pickle\"   ) \n",
    "\n",
    "print(track_time(reset = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15-38-19: Processing and saving archive data on drive... (4.49 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(archivePath):\n",
    "    \"\"\"\n",
    "    ===================================================================================================\n",
    "    ======== CROP USING A MASK (DRAW RED RECTANGLE ON EXPORTED SAMPLE IN MANUAL MASK FOLDER) ==========\n",
    "    IF MASK IS MISSING YOU CAN DRAW IT USING GUI\n",
    "    \"\"\"\n",
    "    if cropMaskMissing: # search for a mask at cropMaskPath (project -> setup -> parameter)\n",
    "        print(f\"\\nNo crop mask in {mainOutputFolder} folder!, creating mask : {cropMaskName}.png\")\n",
    "        mapXY           = (np.load('./mapx.npy'), np.load('./mapy.npy'))\n",
    "        cv2.imwrite(cropMaskPath, convertGray2RGB(undistort(cv2.imread(imageLinks[0],0), mapXY)))\n",
    "\n",
    "        p1,p2           = cropGUI(cropMaskPath)\n",
    "        cropMask        = cv2.imread(cropMaskPath,1)\n",
    "\n",
    "        cv2.rectangle(cropMask, p1, p2,[0,0,255],-1)\n",
    "        cv2.imwrite(  cropMaskPath,cropMask)\n",
    "    else:\n",
    "        cropMask = cv2.imread(cropMaskPath,1)\n",
    "    # ---------------------------- ISOLATE RED RECTANGLE BASED ON ITS HUE ------------------------------\n",
    "    cropMask = cv2.cvtColor(cropMask, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_red = np.array([(0,50,50), (170,50,50)])\n",
    "    upper_red = np.array([(10,255,255), (180,255,255)])\n",
    "\n",
    "    manualMask = cv2.inRange(cropMask, lower_red[0], upper_red[0])\n",
    "    manualMask += cv2.inRange(cropMask, lower_red[1], upper_red[1])\n",
    "\n",
    "    # --------------------- EXTRACT MASK CONTOUR-> BOUNDING RECTANGLE (USED FOR CROP) ------------------\n",
    "    contours = cv2.findContours(manualMask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    [X, Y, W, H] = cv2.boundingRect(contours[0])\n",
    "    \"\"\"\n",
    "    ===================================================================================================\n",
    "    =========================== CROP/UNSISTORT AND STORE DATA INTO ARCHIVES ===========================\n",
    "    ---------------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    print(f\"\\n{timeHMS()}: Processing and saving archive data on drive... {track_time()}\\n\")\n",
    "    \n",
    "    if rotateImageBy % 2 == 0 and rotateImageBy != -1: W,H = H,W     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 185/1999 [00:21<03:33,  8.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m mapXY       \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./mapx.npy\u001b[39m\u001b[38;5;124m'\u001b[39m), np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./mapy.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))            \u001b[38;5;66;03m# fish-eye correction map\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,imageLink \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(imageLinks), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(imageLinks)):\n\u001b[1;32m----> 6\u001b[0m     image \u001b[38;5;241m=\u001b[39m undistort(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimageLink\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, mapXY)[Y:Y\u001b[38;5;241m+\u001b[39mH, X:X\u001b[38;5;241m+\u001b[39mW]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rotateImageBy \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      8\u001b[0m         dataArchive[i]    \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrotate(image, rotateImageBy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataArchive = np.zeros((len(imageLinks),H,W),np.uint8)                  # predefine storage\n",
    "\n",
    "mapXY       = (np.load('./mapx.npy'), np.load('./mapy.npy'))            # fish-eye correction map\n",
    "\n",
    "for i,imageLink in tqdm(enumerate(imageLinks), total=len(imageLinks)):\n",
    "    image = cv2.remap(cv2.imread(imageLink,0), mapXY[0], mapXY[1],cv2.INTER_LINEAR)[Y:Y+H, X:X+W]\n",
    "    #image = undistort(cv2.imread(imageLink,0), mapXY)[Y:Y+H, X:X+W]\n",
    "    if rotateImageBy != -1:\n",
    "        dataArchive[i]    = cv2.rotate(image, rotateImageBy)\n",
    "    else:\n",
    "        dataArchive[i]    = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import worker\n",
    "if __name__ ==  '__main__': \n",
    " num_processors = 3\n",
    " p=Pool(processes = num_processors)\n",
    " output = p.map(worker.worker,[i for i in range(0,3)])\n",
    " print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import worker\n",
    "\n",
    "def a(x):\n",
    "    return worker.worker(x,0)\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    num_processors = 3\n",
    "    p=Pool(processes = num_processors)\n",
    "    output = p.map(a,[i for i in range(0,3)])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArchive = np.zeros((len(imageLinks),H,W),np.uint8)                  # predefine storage\n",
    "from multiprocessing import Pool\n",
    "import worker\n",
    "\n",
    "def a(x):\n",
    "    return worker.worker(x,0)\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    num_processors = 3\n",
    "    p=Pool(processes = num_processors)\n",
    "    output = p.map(a,[i for i in range(0,3)])\n",
    "    print(output)\n",
    "mapXY       = (np.load('./mapx.npy'), np.load('./mapy.npy'))            # fish-eye correction map\n",
    "\n",
    "for i,imageLink in tqdm(enumerate(imageLinks), total=len(imageLinks)):\n",
    "    image = cv2.remap(cv2.imread(imageLink,0), mapXY[0], mapXY[1],cv2.INTER_LINEAR)[Y:Y+H, X:X+W]\n",
    "    #image = undistort(cv2.imread(imageLink,0), mapXY)[Y:Y+H, X:X+W]\n",
    "    if rotateImageBy != -1:\n",
    "        dataArchive[i]    = cv2.rotate(image, rotateImageBy)\n",
    "    else:\n",
    "        dataArchive[i]    = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 4]\n",
      "  [1 3]]\n",
      "\n",
      " [[6 8]\n",
      "  [5 7]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([  [   [1,2],\n",
    "                    [3,4]   ],\n",
    "\n",
    "                [   [5,6],\n",
    "                    [7,8]   ]  ])\n",
    "b = np.rot90(a, 1, (1,2))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weighted Mean: 3.0\n",
      "Actual Mean: 3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b1 = np.mean(a)\n",
    "step = 4\n",
    "num_part = int(np.ceil(len(a) / step))\n",
    "partition = [a[i:i + step] for i in range(0, num_part * step, step)]\n",
    "\n",
    "weighted_mean = 0.0\n",
    "total_weight = 0\n",
    "\n",
    "for part in partition:\n",
    "    part_mean = np.mean(part)\n",
    "    part_weight = len(part)\n",
    "    \n",
    "    weighted_mean = (weighted_mean * total_weight + part_mean * part_weight) / (total_weight + part_weight)\n",
    "    \n",
    "    total_weight += part_weight\n",
    "\n",
    "print(\"Final Weighted Mean:\", weighted_mean)\n",
    "print(\"Actual Mean:\", b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250]\n",
      "[205 215 225 235 245 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      " 255 255 255 255 255 255 255 255]\n",
      "[  0   0   0   0   0 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      " 255 255 255 255 255 255 255 255]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(0,255,10)\n",
    "thld = 50\n",
    "delta = (255-thld)\n",
    "print(a)\n",
    "a += delta\n",
    "a = np.clip(a,0,255)\n",
    "print(a)\n",
    "a = np.where(a >= 255, a, 0)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[1 1 1 0 0]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 1 1]]\n",
      "tensor([[[[1, 1, 1, 0, 0],\n",
      "          [1, 1, 1, 1, 0],\n",
      "          [1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1],\n",
      "          [0, 0, 1, 1, 1]]]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "kernel = np.array([ [1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1] ], dtype=np.float32)#/(9)\n",
    "kernel = np.ones((3,3),np.int16)\n",
    "full_area = np.sum(kernel);print(full_area)\n",
    "\n",
    "im = np.array([ [1, 1, 1, 0, 0],\n",
    "                [1, 1, 1, 1, 0],\n",
    "                [1, 1, 1, 1, 1],\n",
    "                [1, 1, 1, 1, 1],\n",
    "                [0, 0, 1, 1, 1]], dtype=np.int16)\n",
    "\n",
    "im = np.array([ [0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0],\n",
    "                [0, 1, 1, 0, 0],\n",
    "                [0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0] ], dtype=np.int16)\n",
    "\n",
    "\n",
    "\n",
    "mode = 1\n",
    "if mode == 0:\n",
    "    print(cv2.erode(im, kernel, borderValue = 0))\n",
    "else:\n",
    "    print(cv2.dilate(im, kernel, borderValue = 0))\n",
    "\n",
    "def morph_erode_dilate(im_tensor, kernel, mode):\n",
    "    padding = (kernel.shape[-1]//2,)*2#;print(padding)\n",
    "    torch_result0   = torch.nn.functional.conv2d(im_tensor, kernel, padding=padding)\n",
    "    #print(torch_result0)\n",
    "    if mode == 0:\n",
    "        full_area = torch.sum(kernel)\n",
    "        torch_result0.add_(-full_area + 1)\n",
    "        #print(torch_result0)\n",
    "    return torch_result0.clamp_(0, 1)\n",
    "\n",
    "im_tensor       = torch.tensor(im).unsqueeze(0).unsqueeze(0) # size:(1, 1, 5, 5)\n",
    "kernel_tensor   = torch.tensor(kernel).unsqueeze(0).unsqueeze(0) # size: (1, 1, 3, 3)\n",
    "torch_result    = morph_erode_dilate(im_tensor, kernel_tensor, mode = mode)\n",
    "print(torch_result)\n",
    "# if 1 == -1:\n",
    "#     conv            = torch.nn.Conv2d(1, 1, kernel_size = 5, bias = False, padding = 'same', padding_mode ='zeros')\n",
    "#     conv.weight     = torch.nn.Parameter(kernel_tensor) \n",
    "#     torch_result0   = conv(im_tensor).squeeze().squeeze()\n",
    "# else:\n",
    "#     padding = (kernel_tensor.shape[-1]//2,)*2;print(padding)\n",
    "#     torch_result0   = torch.nn.functional.conv2d(im_tensor, kernel_tensor, padding=padding)\n",
    "# print(torch_result0)\n",
    "# torch_result0.add_(-full_area + 1)\n",
    "# torch_result    = torch.clamp(torch_result0, 0, 1)\n",
    "# torch_result0.add_(1.0)\n",
    "# T = torch.nn.Threshold(1, 0, inplace=True)\n",
    "#print(torch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.3 µs ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "im_tensor       = torch.tensor(im).unsqueeze(0).unsqueeze(0) # size:(1, 1, 5, 5)\n",
    "kernel_tensor   = torch.tensor(kernel).unsqueeze(0).unsqueeze(0) # size: (1, 1, 3, 3)\n",
    "torch_result0   = torch.nn.functional.conv2d(im_tensor, kernel_tensor, padding=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 µs ± 7.21 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    im_tensor       = torch.tensor(im).unsqueeze(0).unsqueeze(0) # size:(1, 1, 5, 5)\n",
    "    kernel_tensor   = torch.tensor(kernel).unsqueeze(0).unsqueeze(0) # size: (1, 1, 3, 3)\n",
    "    conv            = torch.nn.Conv2d(1, 1, kernel_size = 5, bias = False, padding = 'same', padding_mode ='zeros')\n",
    "    conv.weight     = torch.nn.Parameter(kernel_tensor) \n",
    "    torch_result0   = conv(im_tensor).squeeze().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5, 5)\n",
      "torch.Size([1000, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "imgs0 =  np.stack([im] * N, axis=0);print(imgs0.shape)\n",
    "kernel = kernel\n",
    "imgs2 = torch.from_numpy(imgs0).unsqueeze(1);print(imgs2.shape)\n",
    "kernel_tensor   = torch.tensor(kernel).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.65625  Kb\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "imgs2 = imgs2.to(device).to(torch.float)\n",
    "kernel_tensor = kernel_tensor.to(device).to(torch.float)\n",
    "print(imgs2.element_size() * imgs2.numel()/ 1024.0,' Kb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.8 µs ± 2.26 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch_result    = morph_erode_dilate(imgs2, kernel_tensor, mode = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.96 ms ± 347 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#dilated_images = np.zeros_like(imgs0)\n",
    "for i in range(N):\n",
    "    imgs0[i] = cv2.dilate(imgs0[i], kernel, borderValue = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch.nn as nn\n",
    "\n",
    "N, H, W = 600, 800, 1200  # Adjust as needed\n",
    "#N, H, W = 1, 4, 4  # Adjust as needed\n",
    "torch.manual_seed(44)\n",
    "# Generate a random tensor with values between 0.0 and 1.0\n",
    "random_tensor = torch.rand(N, H, W)\n",
    "\n",
    "# Scale and shift the values to the desired range [-20.0, 255.0]\n",
    "batch = random_tensor * 275.0 - 30.0\n",
    "batch.to(device)\n",
    "#print(batch)\n",
    "\n",
    "nn_threshold = nn.Threshold(254, 0, inplace=True).to(device)\n",
    "threshold = 50.0\n",
    "nn_threshold1 = nn.Threshold(threshold, 0, inplace=True).to(device)\n",
    "\n",
    "nn_threshold2 = nn.Threshold(0, -255 + 0.001, inplace=True).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 s ± 54.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#print(batch)\n",
    "threshold = 50\n",
    "batch0 = batch.clone()\n",
    "#torch.clamp_(batch0, min = 0, max = 255)\n",
    "delta = (255-threshold + 0.5) # simulate rounding after cast to int by adding 0.5: 0.4->0.9->0 and 0.9->1.4->1\n",
    "batch0.add_(delta)\n",
    "batch0 = batch0.to(torch.int16)\n",
    "#print(batch0)\n",
    "torch.clamp_(batch0, min = 0, max = 255)\n",
    "#print(batch0)\n",
    "nn_threshold(batch0)\n",
    "\n",
    "#print(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [False, False,  True,  ...,  True, False,  True],\n",
      "         [ True,  True, False,  ..., False,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True, False,  ...,  True, False,  True],\n",
      "         [ True, False, False,  ...,  True, False, False],\n",
      "         [ True,  True, False,  ...,  True, False,  True]],\n",
      "\n",
      "        [[ True, False,  True,  ..., False, False,  True],\n",
      "         [False,  True, False,  ...,  True,  True, False],\n",
      "         [ True, False,  True,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [False,  True,  True,  ...,  True,  True, False]],\n",
      "\n",
      "        [[ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ..., False, False,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True, False,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True, False,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ True, False,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [False,  True,  True,  ..., False,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True, False]],\n",
      "\n",
      "        [[ True, False,  True,  ..., False, False,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True, False,  ...,  True, False,  True],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True, False,  ...,  True,  True, False],\n",
      "         [ True,  True, False,  ..., False, False, False]],\n",
      "\n",
      "        [[ True, False, False,  ..., False,  True,  True],\n",
      "         [ True, False,  True,  ...,  True,  True, False],\n",
      "         [False, False, False,  ..., False,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True, False,  ..., False,  True,  True],\n",
      "         [ True,  True,  True,  ..., False,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "#print(batch)\n",
    "threshold = 50\n",
    "\n",
    "batch0 = batch.clone()\n",
    "batch0 = batch0 > threshold\n",
    "# torch.clamp_(batch0, min = threshold, max = None)\n",
    "# #print(batch0)\n",
    "# batch0.add_(-threshold)\n",
    "# #print(batch0)\n",
    "# batch0 = batch0 > 0\n",
    "print(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.5 µs ± 2.31 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#print(batch)\n",
    "batch0 = batch.clone()\n",
    "batch0[batch0 <   threshold]  = 0\n",
    "batch0[batch0 >=  threshold]  = 255\n",
    "#print(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#print(batch)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbatch0 = batch.clone()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mnn_threshold1(batch0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbatch0 *= -1.0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbatch0 += 0.001\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mnn_threshold2(batch0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbatch0 -= 0.001\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mbatch0 *= -1.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#print(batch0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hot Mexican\\VS_Code_Proj\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Hot Mexican\\VS_Code_Proj\\.venv\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1189\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1187\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1189\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[0;32m   1191\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\timeit.py:205\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    203\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m--> 205\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\Hot Mexican\\VS_Code_Proj\\.venv\\lib\\site-packages\\IPython\\core\\magics\\execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:6\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "%%timeit\n",
    "#print(batch)\n",
    "batch0 = batch.clone()\n",
    "nn_threshold1(batch0)\n",
    "\n",
    "batch0 *= -1.0\n",
    "batch0 += 0.001\n",
    "\n",
    "nn_threshold2(batch0)\n",
    "batch0 -= 0.001\n",
    "batch0 *= -1.\n",
    "#print(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 2, 0],\n",
      "          [2, 2, 2],\n",
      "          [0, 2, 0]]]], dtype=torch.uint8)\n",
      "tensor([[[[1.7854, 1.7363],\n",
      "          [1.2084, 1.4256]]],\n",
      "\n",
      "\n",
      "        [[[1.6506, 1.4586],\n",
      "          [1.3093, 1.3809]]],\n",
      "\n",
      "\n",
      "        [[[1.2739, 0.9926],\n",
      "          [1.5014, 1.1683]]]])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def kernle_circular(width):\n",
    "    return torch.from_numpy(cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(width,width))).unsqueeze_(0).unsqueeze_(0)\n",
    "print(kernle_circular(3) + kernle_circular(3))\n",
    "\n",
    "a = torch.rand(3,1,2,2)\n",
    "b = torch.rand(1,1,2,2)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of torch.float element: 4 bytes\n",
      "Size of torch.bool element: 1 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Size of an individual element in bytes for torch.float and torch.bool\n",
    "float_element_size = torch.tensor([1.0], dtype=torch.float).element_size()\n",
    "bool_element_size = torch.tensor([True], dtype=torch.bool).element_size()\n",
    "\n",
    "print(\"Size of torch.float element:\", float_element_size, \"bytes\")\n",
    "print(\"Size of torch.bool element:\", bool_element_size, \"bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 100), (100, 200), (200, 300), (300, 400), (400, 500), (500, 551)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "slice_width = 100\n",
    "\n",
    "data_length = 551\n",
    "\n",
    "def gen_slices(data_length, slice_width):\n",
    "    # input:    data_length, slice_width = 551, 100\n",
    "    # output:   [(0, 100), (100, 200), (200, 300), (300, 400), (400, 500), (500, 551)] \n",
    "    return [(i,min(i+slice_width, data_length)) for i in range(0, data_length, slice_width)]\n",
    "\n",
    "print(gen_slices(data_length, slice_width)) #[(0, 100), (100, 200), (200, 300), (300, 400), (400, 500), (500, 551)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 4, 8], [1, 5], [2, 6], [3, 7]]\n",
      "List 0: [0, 4, 8]\n",
      "List 1: [1, 5]\n",
      "List 2: [2, 6]\n",
      "List 3: [3, 7]\n"
     ]
    }
   ],
   "source": [
    "def redistribute_vals_bins(values, num_lists):\n",
    "    # input: values = [0, 1, 2, 3, 4, 5, 6, 7]; num_lists  = 4\n",
    "    # output : [[0, 4, 8], [1, 5], [2, 6], [3, 7]]\n",
    "    max_bins = min(len(values),num_lists)\n",
    "    lists = [[] for _ in range(max_bins)]\n",
    "    for i, slice_range in enumerate(values):\n",
    "        list_index = i % max_bins\n",
    "        lists[list_index].append(slice_range)\n",
    "    return lists\n",
    "\n",
    "slices = [0,1,2,3,4,5,6,7,8]\n",
    "num_lists = 4\n",
    "redistributed_lists = redistribute_vals_bins(slices, num_lists)\n",
    "print(redistributed_lists)\n",
    "# Print the result\n",
    "for i, lst in enumerate(redistributed_lists):\n",
    "    print(f\"List {i}: {lst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
